{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMWcB0k+phm1Jr+/p59+CiL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "412e8913de6c4adab5e534d9348f37ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20b14a0c17ec45808b5cdcebbcf9aae8",
              "IPY_MODEL_438252923db345b0b1cebcaa2ccc4442",
              "IPY_MODEL_e9962fd822d2407294b7e742814c14da"
            ],
            "layout": "IPY_MODEL_078b73c33a474d6fab65e33dda477b4e"
          }
        },
        "20b14a0c17ec45808b5cdcebbcf9aae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47a0cd03323a41dea85b01629b8093e3",
            "placeholder": "​",
            "style": "IPY_MODEL_b7b96cbf326f4c08ad9227ad663d3303",
            "value": "model.safetensors: 100%"
          }
        },
        "438252923db345b0b1cebcaa2ccc4442": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_841f85f0cc17410bb71e7ed9890e622b",
            "max": 200037522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c27f865dbde343648cada845e92baa08",
            "value": 200037522
          }
        },
        "e9962fd822d2407294b7e742814c14da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f29a0d0a9cd419a8bd00bcf72acd870",
            "placeholder": "​",
            "style": "IPY_MODEL_80242195df714cf98b6945fe242bae06",
            "value": " 200M/200M [00:00&lt;00:00, 354MB/s]"
          }
        },
        "078b73c33a474d6fab65e33dda477b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "47a0cd03323a41dea85b01629b8093e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b96cbf326f4c08ad9227ad663d3303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "841f85f0cc17410bb71e7ed9890e622b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c27f865dbde343648cada845e92baa08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f29a0d0a9cd419a8bd00bcf72acd870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80242195df714cf98b6945fe242bae06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haoyuh3/ai-accelerator/blob/main/multitask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saOVUpAvFZVS",
        "outputId": "a9dab9c4-0b26-4004-afb8-9fa50449a33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "GPU is available.\n",
            "Device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## connect to google drive\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# 检查是否有可用的GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(\"GPU is available.\")\n",
        "    for gpu in gpus:\n",
        "        print(f\"Device: {gpu}\")\n",
        "else:\n",
        "    print(\"No GPU available. Using CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##dataset fer2013\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/haoyuh3/fer2013plus.zip'\n",
        "destination_path = '/content/datasetr'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmquFVsCF7qJ",
        "outputId": "d848fd30-1d2a-4764-d2d8-5f29ebcfc89a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "from google.colab import drive\n",
        "zip_file_path = '/content/drive/MyDrive/haoyuh3/lpfw.zip'\n",
        "destination_path = '/content/lpfw'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_path)"
      ],
      "metadata": {
        "id": "fo6zYUUfFsGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_e_dir = '/content/datasetr/fer2013plus/fer2013/train'\n",
        "test_e_dir = '/content/datasetr/fer2013plus/fer2013/test'\n",
        "\n",
        "train_lp_dir = '/content/lpfw/trainset'\n",
        "test_lp_dir = '/content/lpfw/testset'"
      ],
      "metadata": {
        "id": "gAvlvZYcF3k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e37mNkD9GIDb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a1dGRnp6GIGA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ewjrPNBGIIW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import cv2\n",
        "import numpy as np\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "class LFPWDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = [os.path.join(root_dir, fname) for fname in os.listdir(root_dir) if fname.endswith('.png')]\n",
        "        self.label_paths = [os.path.join(root_dir, os.path.splitext(fname)[0] + '.pts') for fname in os.listdir(root_dir) if fname.endswith('.png')]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label_path = self.label_paths[idx]\n",
        "        image = cv2.imread(image_path)\n",
        "        original_height, original_width = image.shape[:2]\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = Image.fromarray(image)  # 将 numpy 数组转换为 PIL 图像\n",
        "        bbox = self.read_bbox(label_path, original_width, original_height)\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(bbox, dtype=torch.float)\n",
        "\n",
        "    def read_bbox(self, label_path, original_width, original_height):\n",
        "        points = []\n",
        "        with open(label_path, 'r') as file:\n",
        "            lines = file.readlines()[3:71]  # 跳过前3行头信息，读取68个点\n",
        "            for line in lines:\n",
        "                x, y = line.strip().split()\n",
        "                points.append((float(x), float(y)))\n",
        "\n",
        "        points = np.array(points)\n",
        "        x_min = np.min(points[:, 0])\n",
        "        y_min = np.min(points[:, 1])\n",
        "        x_max = np.max(points[:, 0])\n",
        "        y_max = np.max(points[:, 1])\n",
        "        bbox = [x_min, y_min, x_max, y_max]\n",
        "\n",
        "        # Resize bbox to match the transformed image size\n",
        "        bbox = [bbox[0] * 224 / original_width, bbox[1] * 224 / original_height,\n",
        "                bbox[2] * 224 / original_width, bbox[3] * 224 / original_height]\n",
        "        return bbox\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eKXevMUjGIKs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LxdxdqyUGfDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import cv2\n",
        "\n",
        "class FER2013PlusDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.label_map = self._create_label_map()\n",
        "\n",
        "        # 遍历每个表情的文件夹并收集图像路径和标签\n",
        "        for label_name, label_idx in self.label_map.items():\n",
        "            label_dir = os.path.join(root_dir, label_name)\n",
        "            for image_name in os.listdir(label_dir):\n",
        "                image_path = os.path.join(label_dir, image_name)\n",
        "                self.image_paths.append(image_path)\n",
        "                self.labels.append(label_idx)\n",
        "\n",
        "    def _create_label_map(self):\n",
        "        # 根据表情文件夹名创建标签映射\n",
        "        label_names = sorted(os.listdir(self.root_dir))\n",
        "        return {label_name: idx for idx, label_name in enumerate(label_names)}\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, torch.tensor(label, dtype=torch.long)  # 确保标签是长整型张量，并且形状为 (N,)\n",
        "\n",
        "# 使用示例\n",
        "transform_fer = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation(5),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
        "        transforms.RandomResizedCrop(size=224, scale=(0.8, 1.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ],
      "metadata": {
        "id": "WEq1repLGfLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wBXEOa1kHP3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w_1d4HLRHP5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3JS7blTnHP8H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YyK0k-QYLBzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2aMhCNuLB2X",
        "outputId": "fa1d8f27-3fa0-4035-8cb8-e30ff1d98c1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.3 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->timm)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 timm-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T2eqKx4tLLOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "\n",
        "class MultiTaskDataset(Dataset):\n",
        "    def __init__(self, fer_dataset, lfpw_dataset):\n",
        "        self.fer_dataset = fer_dataset\n",
        "        self.lfpw_dataset = lfpw_dataset\n",
        "        self.fer_length = len(fer_dataset)\n",
        "        self.lfpw_length = len(lfpw_dataset)\n",
        "        self.max_length = max(self.fer_length, self.lfpw_length)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.max_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fer_idx = idx % self.fer_length\n",
        "        lfpw_idx = idx % self.lfpw_length\n",
        "\n",
        "        fer_image, fer_label = self.fer_dataset[fer_idx]\n",
        "        lfpw_image, lfpw_bbox = self.lfpw_dataset[lfpw_idx]\n",
        "\n",
        "        return fer_image, fer_label, lfpw_image, lfpw_bbox\n",
        "\n",
        "# 使用示例\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class MultiTaskModel(nn.Module):\n",
        "    def __init__(self, num_classes=8):\n",
        "        super(MultiTaskModel, self).__init__()\n",
        "        # 使用预训练的 Swin Transformer\n",
        "        self.swin = timm.create_model('swin_small_patch4_window7_224', pretrained=True)\n",
        "        swin_in_features = self.swin.head.in_features * 7 * 7  # Assuming output feature map size is 7x7\n",
        "\n",
        "        # 替换分类头\n",
        "        self.swin.head = nn.Identity()\n",
        "\n",
        "        # Flatten the features\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        # 表情识别分类头\n",
        "        self.classifier = nn.Linear(swin_in_features, num_classes)\n",
        "        # 边框回归头\n",
        "        self.bbox_regressor = nn.Linear(swin_in_features, 4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = self.swin.forward_features(x)  # Get features from Swin Transformer\n",
        "        flattened_features = self.flatten(features)\n",
        "\n",
        "        classification = self.classifier(flattened_features)\n",
        "        bbox = self.bbox_regressor(flattened_features)\n",
        "        return classification, bbox\n",
        "\n",
        "# # Example usage\n",
        "# model = MultiTaskModel()\n",
        "# example_input = torch.randn(16, 3, 224, 224)  # Example input shape\n",
        "# classification, bbox = model(example_input)\n",
        "# print(\"Classification shape:\", classification.shape)  # Should be [16, 8]\n",
        "# print(\"BBox shape:\", bbox.shape)  # Should be [16, 4]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau\n",
        "from torch.cuda.amp import GradScaler, autocast\n"
      ],
      "metadata": {
        "id": "hKBBZ30gcVy9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "f4e36bc1-22be-442e-b5a3-9bada8733ffb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'Dataset' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-dfbf5bc97f0a>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMultiTaskDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfer_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlfpw_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfer_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfer_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Dataset' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FER2013Plus 数据集\n",
        "fer2013plus_root_dir = train_e_dir  # 修改为你的FER2013Plus数据集路径\n",
        "fer_dataset = FER2013PlusDataset(root_dir=fer2013plus_root_dir, transform=transform_fer['train'])\n",
        "\n",
        "# LFPW 数据集\n",
        "lfpw_root_dir = train_lp_dir  # 修改为你的LFPW数据集路径\n",
        "lfpw_dataset = LFPWDataset(root_dir=lfpw_root_dir, transform=transform)\n",
        "\n",
        "# 创建多任务数据集\n",
        "multi_task_dataset = MultiTaskDataset(fer_dataset, lfpw_dataset)\n",
        "\n",
        "# 创建数据加载器\n",
        "data_loader = DataLoader(multi_task_dataset, batch_size=16, shuffle=True)\n"
      ],
      "metadata": {
        "id": "QfzJG4tjcdnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def normalize_bbox(bboxes, image_size):\n",
        "    height, width = image_size\n",
        "    bboxes[:, 0] /= width  # Normalize x1\n",
        "    bboxes[:, 1] /= height  # Normalize y1\n",
        "    bboxes[:, 2] /= width  # Normalize x2\n",
        "    bboxes[:, 3] /= height  # Normalize y2\n",
        "    return bboxes\n",
        "\n",
        "def denormalize_bbox(bboxes, image_size):\n",
        "    height, width = image_size\n",
        "    bboxes[:, 0] *= width\n",
        "    bboxes[:, 1] *= height\n",
        "    bboxes[:, 2] *= width\n",
        "    bboxes[:, 3] *= height\n",
        "    return bboxes\n",
        "\n"
      ],
      "metadata": {
        "id": "tRUzsB5-iVE3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UMWsZYU9iYuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train_model(model, dataloader, criterion_classification, criterion_regression, optimizer, scheduler, scaler, num_epochs=10, device='cuda'):\n",
        "    model = model.to(device)\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        model.train()  # Training mode\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data with a progress bar\n",
        "        for fer_images, fer_labels, lfpw_images, lfpw_bboxes in tqdm(dataloader, desc=f'Epoch {epoch}/{num_epochs - 1}'):\n",
        "            fer_images = fer_images.to(device)\n",
        "            fer_labels = fer_labels.to(device)\n",
        "            lfpw_images = lfpw_images.to(device)\n",
        "            lfpw_bboxes = lfpw_bboxes.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            with autocast():\n",
        "                # Expression recognition task\n",
        "                outputs_classification, _ = model(fer_images)\n",
        "                loss_classification = criterion_classification(outputs_classification, fer_labels)\n",
        "\n",
        "                # Bounding box regression task\n",
        "                _, outputs_regression = model(lfpw_images)\n",
        "                image_size = lfpw_images.size(2), lfpw_images.size(3)\n",
        "                normalized_lfpw_bboxes = normalize_bbox(lfpw_bboxes, image_size)\n",
        "\n",
        "                loss_regression = criterion_regression(outputs_regression, normalized_lfpw_bboxes)\n",
        "\n",
        "                # Total loss\n",
        "                loss = loss_classification + loss_regression\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            running_loss += loss.item() * fer_images.size(0)\n",
        "            running_corrects += torch.sum(torch.argmax(outputs_classification, dim=1) == fer_labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "        print(f'Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "        # Deep copy the model\n",
        "        if epoch_acc > best_acc:\n",
        "            best_acc = epoch_acc\n",
        "            best_model_wts = model.state_dict()\n",
        "\n",
        "        scheduler.step()\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(f'Best Train Acc: {best_acc:.4f}')\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# 训练模型\n",
        "model = MultiTaskModel(num_classes=8)\n",
        "criterion_classification = nn.CrossEntropyLoss()\n",
        "criterion_regression = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
        "# 学习率调度器\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "# 使用混合精度训练\n",
        "scaler = GradScaler()\n",
        "model = train_model(model, data_loader, criterion_classification, criterion_regression, optimizer, scheduler, scaler, num_epochs=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "412e8913de6c4adab5e534d9348f37ef",
            "20b14a0c17ec45808b5cdcebbcf9aae8",
            "438252923db345b0b1cebcaa2ccc4442",
            "e9962fd822d2407294b7e742814c14da",
            "078b73c33a474d6fab65e33dda477b4e",
            "47a0cd03323a41dea85b01629b8093e3",
            "b7b96cbf326f4c08ad9227ad663d3303",
            "841f85f0cc17410bb71e7ed9890e622b",
            "c27f865dbde343648cada845e92baa08",
            "4f29a0d0a9cd419a8bd00bcf72acd870",
            "80242195df714cf98b6945fe242bae06"
          ]
        },
        "id": "UwaduePYMpn7",
        "outputId": "b33dbbd0-d8d7-403f-d290-8618c35ede4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/200M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "412e8913de6c4adab5e534d9348f37ef"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 0/9: 100%|██████████| 1775/1775 [15:24<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.8578 Acc: 0.7017\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/9: 100%|██████████| 1775/1775 [15:21<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6450 Acc: 0.7744\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/9: 100%|██████████| 1775/1775 [15:23<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5665 Acc: 0.8003\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/9: 100%|██████████| 1775/1775 [15:12<00:00,  1.95it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5057 Acc: 0.8214\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/9: 100%|██████████| 1775/1775 [15:13<00:00,  1.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.4387 Acc: 0.8441\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/9: 100%|██████████| 1775/1775 [15:22<00:00,  1.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3712 Acc: 0.8682\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/9: 100%|██████████| 1775/1775 [15:20<00:00,  1.93it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.3129 Acc: 0.8857\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 7/9: 100%|██████████| 1775/1775 [15:41<00:00,  1.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2622 Acc: 0.9050\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 8/9: 100%|██████████| 1775/1775 [15:35<00:00,  1.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2248 Acc: 0.9190\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 9/9: 100%|██████████| 1775/1775 [15:39<00:00,  1.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.2001 Acc: 0.9263\n",
            "\n",
            "Best Train Acc: 0.9263\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# FER2013Plus 数据集\n",
        "fer2013plus_root_dir = test_e_dir  # 修改为你的FER2013Plus数据集路径\n",
        "fer_dataset = FER2013PlusDataset(root_dir=fer2013plus_root_dir, transform=transform_fer['train'])\n",
        "\n",
        "# LFPW 数据集\n",
        "lfpw_root_dir = test_lp_dir  # 修改为你的LFPW数据集路径\n",
        "lfpw_dataset = LFPWDataset(root_dir=lfpw_root_dir, transform=transform)\n",
        "\n",
        "# 创建多任务数据集\n",
        "multi_task_dataset_test = MultiTaskDataset(fer_dataset, lfpw_dataset)\n",
        "\n",
        "# 创建数据加载器\n",
        "data_loader_test = DataLoader(multi_task_dataset_test, batch_size=16, shuffle=True)"
      ],
      "metadata": {
        "id": "5ienNt3oKmEY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "test_corrects = 0\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "for inputs, labels, lfpw_images, lfpw_bboxes in tqdm(data_loader_test, desc='Testing'):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs,_ = model(inputs)\n",
        "    lfpw_images = lfpw_images.to(device)\n",
        "    lfpw_bboxes = lfpw_bboxes.to(device)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    test_corrects += torch.sum(preds == labels.data)\n",
        "\n"
      ],
      "metadata": {
        "id": "_TJETTkZLKvO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b383311-a0cf-4f52-8c1a-db2d01b5fc51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 444/444 [02:31<00:00,  2.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = test_corrects.double() / len(data_loader_test.dataset)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AX6hBtCMryE",
        "outputId": "b93c2deb-fbfa-40df-c4c6-41f2886eb23f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.8410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'swing_trans_multi.pth')"
      ],
      "metadata": {
        "id": "q7KOt_epJtdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MultiTaskModel(num_classes=8)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/haoyuh3/swing_trans_multi.pth'))\n",
        "criterion_classification = nn.CrossEntropyLoss()\n",
        "criterion_regression = nn.MSELoss()\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-8, weight_decay=1e-2)\n",
        "# 学习率调度器\n",
        "scheduler = CosineAnnealingLR(optimizer, T_max=10)\n",
        "\n",
        "# 使用混合精度训练\n",
        "scaler = GradScaler()\n",
        "model = train_model(model, data_loader, criterion_classification, criterion_regression, optimizer, scheduler, scaler, num_epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "3LI0DGaYNdzu",
        "outputId": "3674f049-d0f5-45b3-b33a-6ed92699024c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'MultiTaskModel' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-c1eab1398716>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultiTaskModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/haoyuh3/swing_trans_multi.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcriterion_classification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion_regression\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdamW\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'MultiTaskModel' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D4z2s43uNd-2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}