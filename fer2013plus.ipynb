{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMvqPY9ySknZNapv2CY/j9m",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/haoyuh3/ai-accelerator/blob/main/fer2013plus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sxtkQ_YRUu1i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c29df5ae-6c73-4462-efdb-6f0fc968d114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "GPU is available.\n",
            "Device: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## connect to google drive\n",
        "\n",
        "train_dir = '/content/datasetr/fer2013/train'\n",
        "test_dir = '/content/datasetr/fer2013/test'\n",
        "import tensorflow as tf\n",
        "\n",
        "# 检查是否有可用的GPU\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    print(\"GPU is available.\")\n",
        "    for gpu in gpus:\n",
        "        print(f\"Device: {gpu}\")\n",
        "else:\n",
        "    print(\"No GPU available. Using CPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##dataset fer2013\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "zip_file_path = '/content/drive/MyDrive/haoyuh3/fer2013plus.zip'\n",
        "destination_path = '/content/datasetr'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination_path)\n"
      ],
      "metadata": {
        "id": "QhBgVXkqVBJf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e125252a-27c4-46ec-968f-3e836bb76da3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/datasetr/fer2013plus/fer2013/train'\n",
        "test_dir = '/content/datasetr/fer2013plus/fer2013/test'"
      ],
      "metadata": {
        "id": "tW5oYt4jV6_0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization, Activation, multiply, concatenate, Input\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Multiply, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "def InceptionV3_mine(\n",
        "    include_top=True,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=7,\n",
        "    classifier_activation=\"softmax\",\n",
        "):\n",
        "\n",
        "\n",
        "    channel_axis = 3\n",
        "    img_input = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding=\"valid\")\n",
        "    x = conv2d_bn(x, 32, 3, 3, padding=\"valid\")\n",
        "    x = conv2d_bn(x, 64, 3, 3)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv2d_bn(x, 80, 1, 1, padding=\"valid\")\n",
        "    x = conv2d_bn(x, 192, 3, 3, padding=\"valid\")\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    # mixed 0: 35 x 35 x 256\n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed0\",\n",
        "    )\n",
        "\n",
        "\n",
        "    # mixed 1: 35 x 35 x 288\n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed1\",\n",
        "    )\n",
        "\n",
        "\n",
        "    # mixed 2: 35 x 35 x 288\n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed2\",\n",
        "    )\n",
        "\n",
        "    # mixed 3: 17 x 17 x 768\n",
        "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding=\"valid\")\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(\n",
        "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding=\"valid\"\n",
        "    )\n",
        "\n",
        "    branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = layers.concatenate(\n",
        "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name=\"mixed3\"\n",
        "    )\n",
        "\n",
        "    # mixed 4: 17 x 17 x 768\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed4\",\n",
        "    )\n",
        "\n",
        "    # mixed 5, 6: 17 x 17 x 768\n",
        "    for i in range(2):\n",
        "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding=\"same\"\n",
        "        )(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate(\n",
        "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name=\"mixed\" + str(5 + i),\n",
        "        )\n",
        "\n",
        "    # mixed 7: 17 x 17 x 768\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed7\",\n",
        "    )\n",
        "\n",
        "    # mixed 8: 8 x 8 x 1280\n",
        "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3, strides=(2, 2), padding=\"valid\")\n",
        "\n",
        "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
        "    branch7x7x3 = conv2d_bn(\n",
        "        branch7x7x3, 192, 3, 3, strides=(2, 2), padding=\"valid\"\n",
        "    )\n",
        "\n",
        "    branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = layers.concatenate(\n",
        "        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name=\"mixed8\"\n",
        "    )\n",
        "\n",
        "    # mixed 9: 8 x 8 x 2048\n",
        "    for i in range(2):\n",
        "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
        "\n",
        "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
        "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
        "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
        "        branch3x3 = layers.concatenate(\n",
        "            [branch3x3_1, branch3x3_2],\n",
        "            axis=channel_axis,\n",
        "            name=\"mixed9_\" + str(i),\n",
        "        )\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
        "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
        "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
        "        branch3x3dbl = layers.concatenate(\n",
        "            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis\n",
        "        )\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding=\"same\"\n",
        "        )(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate(\n",
        "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name=\"mixed\" + str(9 + i),\n",
        "        )\n",
        "\n",
        "        if pooling == \"avg\":\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == \"max\":\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output_tensor = Dense(classes, activation='softmax')(x)  # 假设有7个类别\n",
        "\n",
        "    model = Model(inputs=img_input, outputs=output_tensor)\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def conv2d_bn(\n",
        "    x, filters, num_row, num_col, padding=\"same\", strides=(1, 1), name=None\n",
        "):\n",
        "    \"\"\"Utility function to apply conv + BN.\n",
        "\n",
        "    Args:\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv2D`.\n",
        "        num_row: height of the convolution kernel.\n",
        "        num_col: width of the convolution kernel.\n",
        "        padding: padding mode in `Conv2D`.\n",
        "        strides: strides in `Conv2D`.\n",
        "        name: name of the ops; will become `name + '_conv'`\n",
        "            for the convolution and `name + '_bn'` for the\n",
        "            batch norm layer.\n",
        "\n",
        "    Returns:\n",
        "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    if name is not None:\n",
        "        bn_name = name + \"_bn\"\n",
        "        conv_name = name + \"_conv\"\n",
        "    else:\n",
        "        bn_name = None\n",
        "        conv_name = None\n",
        "\n",
        "    x = layers.Conv2D(\n",
        "        filters,\n",
        "        (num_row, num_col),\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        use_bias=False,\n",
        "        name=conv_name,\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(axis=3, scale=False, name=bn_name)(x)\n",
        "    x = layers.Activation(\"relu\", name=name)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "JZkCyXDlWBYs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W9nUtxUdau7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def spatial_attention_module(input_feature):\n",
        "    kernel_size = 7\n",
        "\n",
        "    avg_pool = tf.reduce_mean(input_feature, axis=3, keepdims=True)\n",
        "    max_pool = tf.reduce_max(input_feature, axis=3, keepdims=True)\n",
        "    concat = concatenate([avg_pool, max_pool], axis=3)\n",
        "    attention = Conv2D(1, (kernel_size, kernel_size), padding='same', activation='sigmoid', kernel_initializer='he_normal', use_bias=False)(concat)\n",
        "    output = multiply([input_feature, attention])\n",
        "    return output"
      ],
      "metadata": {
        "id": "o3oVNxv_au-X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, GlobalAveragePooling2D, BatchNormalization, Activation, multiply, concatenate, Input\n",
        "\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, GlobalAveragePooling2D, Dense, Multiply, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "def InceptionV3_mine(\n",
        "    include_top=True,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=7,\n",
        "    classifier_activation=\"softmax\",\n",
        "):\n",
        "\n",
        "\n",
        "    channel_axis = 3\n",
        "    img_input = layers.Input(shape=input_shape)\n",
        "\n",
        "    x = conv2d_bn(img_input, 32, 3, 3, strides=(2, 2), padding=\"valid\")\n",
        "    x = conv2d_bn(x, 32, 3, 3, padding=\"valid\")\n",
        "    x = conv2d_bn(x, 64, 3, 3)\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    x = conv2d_bn(x, 80, 1, 1, padding=\"valid\")\n",
        "    x = conv2d_bn(x, 192, 3, 3, padding=\"valid\")\n",
        "    x = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "    # mixed 0: 35 x 35 x 256\n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed0\",\n",
        "    )\n",
        "\n",
        "    x = spatial_attention_module(x)\n",
        "    x = layers.Lambda(lambda y: y, name=\"attention0\")(x)  # Naming the attention module\n",
        "\n",
        "    # mixed 1: 35 x 35 x 288\n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed1\",\n",
        "    )\n",
        "\n",
        "    x = spatial_attention_module(x)\n",
        "    x = layers.Lambda(lambda y: y, name=\"attention1\")(x)  # Naming the attention module\n",
        "\n",
        "    # mixed 2: 35 x 35 x 288\n",
        "    branch1x1 = conv2d_bn(x, 64, 1, 1)\n",
        "\n",
        "    branch5x5 = conv2d_bn(x, 48, 1, 1)\n",
        "    branch5x5 = conv2d_bn(branch5x5, 64, 5, 5)\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 64, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch5x5, branch3x3dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed2\",\n",
        "    )\n",
        "    x = spatial_attention_module(x)\n",
        "    x = layers.Lambda(lambda y: y, name=\"attention2\")(x)  # Naming the attention module\n",
        "\n",
        "\n",
        "    # mixed 3: 17 x 17 x 768\n",
        "    branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding=\"valid\")\n",
        "\n",
        "    branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
        "    branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
        "    branch3x3dbl = conv2d_bn(\n",
        "        branch3x3dbl, 96, 3, 3, strides=(2, 2), padding=\"valid\"\n",
        "    )\n",
        "\n",
        "    branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = layers.concatenate(\n",
        "        [branch3x3, branch3x3dbl, branch_pool], axis=channel_axis, name=\"mixed3\"\n",
        "    )\n",
        "    x = spatial_attention_module(x)\n",
        "    x = layers.Lambda(lambda y: y, name=\"attention3\")(x)  # Naming the attention module\n",
        "    # mixed 4: 17 x 17 x 768\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 128, 1, 7)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 128, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed4\",\n",
        "    )\n",
        "    x = spatial_attention_module(x)\n",
        "    x = layers.Lambda(lambda y: y, name=\"attention4\")(x)  # Naming the attention module\n",
        "\n",
        "    # mixed 5, 6: 17 x 17 x 768\n",
        "    for i in range(2):\n",
        "        branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "        branch7x7 = conv2d_bn(x, 160, 1, 1)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 160, 1, 7)\n",
        "        branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "        branch7x7dbl = conv2d_bn(x, 160, 1, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 1, 7)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 160, 7, 1)\n",
        "        branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding=\"same\"\n",
        "        )(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate(\n",
        "            [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name=\"mixed\" + str(5 + i),\n",
        "        )\n",
        "\n",
        "    # mixed 7: 17 x 17 x 768\n",
        "    branch1x1 = conv2d_bn(x, 192, 1, 1)\n",
        "\n",
        "    branch7x7 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 1, 7)\n",
        "    branch7x7 = conv2d_bn(branch7x7, 192, 7, 1)\n",
        "\n",
        "    branch7x7dbl = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 7, 1)\n",
        "    branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7)\n",
        "\n",
        "    branch_pool = layers.AveragePooling2D(\n",
        "        (3, 3), strides=(1, 1), padding=\"same\"\n",
        "    )(x)\n",
        "    branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "    x = layers.concatenate(\n",
        "        [branch1x1, branch7x7, branch7x7dbl, branch_pool],\n",
        "        axis=channel_axis,\n",
        "        name=\"mixed7\",\n",
        "    )\n",
        "\n",
        "    # mixed 8: 8 x 8 x 1280\n",
        "    branch3x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch3x3 = conv2d_bn(branch3x3, 320, 3, 3, strides=(2, 2), padding=\"valid\")\n",
        "\n",
        "    branch7x7x3 = conv2d_bn(x, 192, 1, 1)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 1, 7)\n",
        "    branch7x7x3 = conv2d_bn(branch7x7x3, 192, 7, 1)\n",
        "    branch7x7x3 = conv2d_bn(\n",
        "        branch7x7x3, 192, 3, 3, strides=(2, 2), padding=\"valid\"\n",
        "    )\n",
        "\n",
        "    branch_pool = layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "    x = layers.concatenate(\n",
        "        [branch3x3, branch7x7x3, branch_pool], axis=channel_axis, name=\"mixed8\"\n",
        "    )\n",
        "\n",
        "    # mixed 9: 8 x 8 x 2048\n",
        "    for i in range(2):\n",
        "        branch1x1 = conv2d_bn(x, 320, 1, 1)\n",
        "\n",
        "        branch3x3 = conv2d_bn(x, 384, 1, 1)\n",
        "        branch3x3_1 = conv2d_bn(branch3x3, 384, 1, 3)\n",
        "        branch3x3_2 = conv2d_bn(branch3x3, 384, 3, 1)\n",
        "        branch3x3 = layers.concatenate(\n",
        "            [branch3x3_1, branch3x3_2],\n",
        "            axis=channel_axis,\n",
        "            name=\"mixed9_\" + str(i),\n",
        "        )\n",
        "\n",
        "        branch3x3dbl = conv2d_bn(x, 448, 1, 1)\n",
        "        branch3x3dbl = conv2d_bn(branch3x3dbl, 384, 3, 3)\n",
        "        branch3x3dbl_1 = conv2d_bn(branch3x3dbl, 384, 1, 3)\n",
        "        branch3x3dbl_2 = conv2d_bn(branch3x3dbl, 384, 3, 1)\n",
        "        branch3x3dbl = layers.concatenate(\n",
        "            [branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis\n",
        "        )\n",
        "\n",
        "        branch_pool = layers.AveragePooling2D(\n",
        "            (3, 3), strides=(1, 1), padding=\"same\"\n",
        "        )(x)\n",
        "        branch_pool = conv2d_bn(branch_pool, 192, 1, 1)\n",
        "        x = layers.concatenate(\n",
        "            [branch1x1, branch3x3, branch3x3dbl, branch_pool],\n",
        "            axis=channel_axis,\n",
        "            name=\"mixed\" + str(9 + i),\n",
        "        )\n",
        "\n",
        "        if pooling == \"avg\":\n",
        "            x = layers.GlobalAveragePooling2D()(x)\n",
        "        elif pooling == \"max\":\n",
        "            x = layers.GlobalMaxPooling2D()(x)\n",
        "\n",
        "\n",
        "    x = Flatten()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(4096, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = Dense(1024, activation='relu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output_tensor = Dense(classes, activation='softmax')(x)  # 假设有7个类别\n",
        "\n",
        "    model = Model(inputs=img_input, outputs=output_tensor)\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def conv2d_bn(\n",
        "    x, filters, num_row, num_col, padding=\"same\", strides=(1, 1), name=None\n",
        "):\n",
        "    \"\"\"Utility function to apply conv + BN.\n",
        "\n",
        "    Args:\n",
        "        x: input tensor.\n",
        "        filters: filters in `Conv2D`.\n",
        "        num_row: height of the convolution kernel.\n",
        "        num_col: width of the convolution kernel.\n",
        "        padding: padding mode in `Conv2D`.\n",
        "        strides: strides in `Conv2D`.\n",
        "        name: name of the ops; will become `name + '_conv'`\n",
        "            for the convolution and `name + '_bn'` for the\n",
        "            batch norm layer.\n",
        "\n",
        "    Returns:\n",
        "        Output tensor after applying `Conv2D` and `BatchNormalization`.\n",
        "    \"\"\"\n",
        "    if name is not None:\n",
        "        bn_name = name + \"_bn\"\n",
        "        conv_name = name + \"_conv\"\n",
        "    else:\n",
        "        bn_name = None\n",
        "        conv_name = None\n",
        "\n",
        "    x = layers.Conv2D(\n",
        "        filters,\n",
        "        (num_row, num_col),\n",
        "        strides=strides,\n",
        "        padding=padding,\n",
        "        use_bias=False,\n",
        "        name=conv_name,\n",
        "    )(x)\n",
        "    x = layers.BatchNormalization(axis=3, scale=False, name=bn_name)(x)\n",
        "    x = layers.Activation(\"relu\", name=name)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "HCaZmlihavBB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eC2NpEbcavDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qN_aYxJ3avGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "        validation_split = 0.2,\n",
        "        rotation_range=5,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  validation_split = 0.2)\n",
        "\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255\n",
        "                                  )\n",
        "\n",
        "train_dataset  = train_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                   target_size = (75,75),\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset = 'training',\n",
        "                                                   batch_size = 64)\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                  target_size = (75,75),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  subset = 'validation',\n",
        "                                                  batch_size = 64)\n",
        "\n",
        "test_dataset = test_datagen.flow_from_directory(directory = test_dir,\n",
        "                                                  target_size = (75,75),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  batch_size = 64)\n",
        "\n",
        "base_model = InceptionV3_mine(input_shape=(75,75,3), classes = 8)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print(base_model.layers[18].trainable)\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "        f1_score,\n",
        "]\n",
        "\n",
        "lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-5)\n",
        "\n",
        "mcp = ModelCheckpoint('model.h5')\n",
        "\n",
        "es = EarlyStopping(verbose=1, patience=20)\n",
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)\n",
        "\n",
        "history=model.fit(train_dataset,validation_data=valid_dataset,epochs = 10,verbose = 1,callbacks=[lrd,mcp,es])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFvpALcWWKC6",
        "outputId": "42e31f9d-0b48-49dc-9985-ec8d49726d52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22712 images belonging to 8 classes.\n",
            "Found 5674 images belonging to 8 classes.\n",
            "Found 7099 images belonging to 8 classes.\n",
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_5 (InputLayer)        [(None, 75, 75, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_376 (Conv2D)         (None, 37, 37, 32)           864       ['input_5[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_376 (B  (None, 37, 37, 32)           96        ['conv2d_376[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_376 (Activation  (None, 37, 37, 32)           0         ['batch_normalization_376[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_377 (Conv2D)         (None, 35, 35, 32)           9216      ['activation_376[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_377 (B  (None, 35, 35, 32)           96        ['conv2d_377[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_377 (Activation  (None, 35, 35, 32)           0         ['batch_normalization_377[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_378 (Conv2D)         (None, 35, 35, 64)           18432     ['activation_377[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_378 (B  (None, 35, 35, 64)           192       ['conv2d_378[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_378 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_378[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_16 (MaxPooli  (None, 17, 17, 64)           0         ['activation_378[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_379 (Conv2D)         (None, 17, 17, 80)           5120      ['max_pooling2d_16[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_379 (B  (None, 17, 17, 80)           240       ['conv2d_379[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_379 (Activation  (None, 17, 17, 80)           0         ['batch_normalization_379[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_380 (Conv2D)         (None, 15, 15, 192)          138240    ['activation_379[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_380 (B  (None, 15, 15, 192)          576       ['conv2d_380[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_380 (Activation  (None, 15, 15, 192)          0         ['batch_normalization_380[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_17 (MaxPooli  (None, 7, 7, 192)            0         ['activation_380[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_384 (Conv2D)         (None, 7, 7, 64)             12288     ['max_pooling2d_17[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_384 (B  (None, 7, 7, 64)             192       ['conv2d_384[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_384 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_384[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_382 (Conv2D)         (None, 7, 7, 48)             9216      ['max_pooling2d_17[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_385 (Conv2D)         (None, 7, 7, 96)             55296     ['activation_384[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_382 (B  (None, 7, 7, 48)             144       ['conv2d_382[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_385 (B  (None, 7, 7, 96)             288       ['conv2d_385[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_382 (Activation  (None, 7, 7, 48)             0         ['batch_normalization_382[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_385 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_385[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_36 (Aver  (None, 7, 7, 192)            0         ['max_pooling2d_17[0][0]']    \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_381 (Conv2D)         (None, 7, 7, 64)             12288     ['max_pooling2d_17[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_383 (Conv2D)         (None, 7, 7, 64)             76800     ['activation_382[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_386 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_385[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_387 (Conv2D)         (None, 7, 7, 32)             6144      ['average_pooling2d_36[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_381 (B  (None, 7, 7, 64)             192       ['conv2d_381[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_383 (B  (None, 7, 7, 64)             192       ['conv2d_383[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_386 (B  (None, 7, 7, 96)             288       ['conv2d_386[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_387 (B  (None, 7, 7, 32)             96        ['conv2d_387[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_381 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_381[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_383 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_383[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_386 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_386[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_387 (Activation  (None, 7, 7, 32)             0         ['batch_normalization_387[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 7, 7, 256)            0         ['activation_381[0][0]',      \n",
            "                                                                     'activation_383[0][0]',      \n",
            "                                                                     'activation_386[0][0]',      \n",
            "                                                                     'activation_387[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_391 (Conv2D)         (None, 7, 7, 64)             16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_391 (B  (None, 7, 7, 64)             192       ['conv2d_391[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_391 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_391[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_389 (Conv2D)         (None, 7, 7, 48)             12288     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_392 (Conv2D)         (None, 7, 7, 96)             55296     ['activation_391[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_389 (B  (None, 7, 7, 48)             144       ['conv2d_389[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_392 (B  (None, 7, 7, 96)             288       ['conv2d_392[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_389 (Activation  (None, 7, 7, 48)             0         ['batch_normalization_389[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_392 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_392[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_37 (Aver  (None, 7, 7, 256)            0         ['mixed0[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_388 (Conv2D)         (None, 7, 7, 64)             16384     ['mixed0[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_390 (Conv2D)         (None, 7, 7, 64)             76800     ['activation_389[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_393 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_392[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_394 (Conv2D)         (None, 7, 7, 64)             16384     ['average_pooling2d_37[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_388 (B  (None, 7, 7, 64)             192       ['conv2d_388[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_390 (B  (None, 7, 7, 64)             192       ['conv2d_390[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_393 (B  (None, 7, 7, 96)             288       ['conv2d_393[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_394 (B  (None, 7, 7, 64)             192       ['conv2d_394[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_388 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_388[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_390 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_390[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_393 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_393[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_394 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_394[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 7, 7, 288)            0         ['activation_388[0][0]',      \n",
            "                                                                     'activation_390[0][0]',      \n",
            "                                                                     'activation_393[0][0]',      \n",
            "                                                                     'activation_394[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_398 (Conv2D)         (None, 7, 7, 64)             18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_398 (B  (None, 7, 7, 64)             192       ['conv2d_398[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_398 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_398[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_396 (Conv2D)         (None, 7, 7, 48)             13824     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_399 (Conv2D)         (None, 7, 7, 96)             55296     ['activation_398[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_396 (B  (None, 7, 7, 48)             144       ['conv2d_396[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_399 (B  (None, 7, 7, 96)             288       ['conv2d_399[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_396 (Activation  (None, 7, 7, 48)             0         ['batch_normalization_396[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_399 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_399[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_38 (Aver  (None, 7, 7, 288)            0         ['mixed1[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_395 (Conv2D)         (None, 7, 7, 64)             18432     ['mixed1[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_397 (Conv2D)         (None, 7, 7, 64)             76800     ['activation_396[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_400 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_399[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_401 (Conv2D)         (None, 7, 7, 64)             18432     ['average_pooling2d_38[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_395 (B  (None, 7, 7, 64)             192       ['conv2d_395[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_397 (B  (None, 7, 7, 64)             192       ['conv2d_397[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_400 (B  (None, 7, 7, 96)             288       ['conv2d_400[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_401 (B  (None, 7, 7, 64)             192       ['conv2d_401[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_395 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_395[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_397 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_397[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_400 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_400[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_401 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_401[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 7, 7, 288)            0         ['activation_395[0][0]',      \n",
            "                                                                     'activation_397[0][0]',      \n",
            "                                                                     'activation_400[0][0]',      \n",
            "                                                                     'activation_401[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_403 (Conv2D)         (None, 7, 7, 64)             18432     ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_403 (B  (None, 7, 7, 64)             192       ['conv2d_403[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_403 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_403[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_404 (Conv2D)         (None, 7, 7, 96)             55296     ['activation_403[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_404 (B  (None, 7, 7, 96)             288       ['conv2d_404[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_404 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_404[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_402 (Conv2D)         (None, 3, 3, 384)            995328    ['mixed2[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_405 (Conv2D)         (None, 3, 3, 96)             82944     ['activation_404[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_402 (B  (None, 3, 3, 384)            1152      ['conv2d_402[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_405 (B  (None, 3, 3, 96)             288       ['conv2d_405[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_402 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_402[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_405 (Activation  (None, 3, 3, 96)             0         ['batch_normalization_405[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_18 (MaxPooli  (None, 3, 3, 288)            0         ['mixed2[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 3, 3, 768)            0         ['activation_402[0][0]',      \n",
            "                                                                     'activation_405[0][0]',      \n",
            "                                                                     'max_pooling2d_18[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_410 (Conv2D)         (None, 3, 3, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_410 (B  (None, 3, 3, 128)            384       ['conv2d_410[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_410 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_410[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_411 (Conv2D)         (None, 3, 3, 128)            114688    ['activation_410[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_411 (B  (None, 3, 3, 128)            384       ['conv2d_411[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_411 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_411[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_407 (Conv2D)         (None, 3, 3, 128)            98304     ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_412 (Conv2D)         (None, 3, 3, 128)            114688    ['activation_411[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_407 (B  (None, 3, 3, 128)            384       ['conv2d_407[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_412 (B  (None, 3, 3, 128)            384       ['conv2d_412[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_407 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_407[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_412 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_412[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_408 (Conv2D)         (None, 3, 3, 128)            114688    ['activation_407[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_413 (Conv2D)         (None, 3, 3, 128)            114688    ['activation_412[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_408 (B  (None, 3, 3, 128)            384       ['conv2d_408[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_413 (B  (None, 3, 3, 128)            384       ['conv2d_413[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_408 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_408[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_413 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_413[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_39 (Aver  (None, 3, 3, 768)            0         ['mixed3[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_406 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed3[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_409 (Conv2D)         (None, 3, 3, 192)            172032    ['activation_408[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_414 (Conv2D)         (None, 3, 3, 192)            172032    ['activation_413[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_415 (Conv2D)         (None, 3, 3, 192)            147456    ['average_pooling2d_39[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_406 (B  (None, 3, 3, 192)            576       ['conv2d_406[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_409 (B  (None, 3, 3, 192)            576       ['conv2d_409[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_414 (B  (None, 3, 3, 192)            576       ['conv2d_414[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_415 (B  (None, 3, 3, 192)            576       ['conv2d_415[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_406 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_406[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_409 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_409[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_414 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_414[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_415 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_415[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 3, 3, 768)            0         ['activation_406[0][0]',      \n",
            "                                                                     'activation_409[0][0]',      \n",
            "                                                                     'activation_414[0][0]',      \n",
            "                                                                     'activation_415[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_420 (Conv2D)         (None, 3, 3, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_420 (B  (None, 3, 3, 160)            480       ['conv2d_420[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_420 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_420[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_421 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_420[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_421 (B  (None, 3, 3, 160)            480       ['conv2d_421[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_421 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_421[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_417 (Conv2D)         (None, 3, 3, 160)            122880    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_422 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_421[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_417 (B  (None, 3, 3, 160)            480       ['conv2d_417[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_422 (B  (None, 3, 3, 160)            480       ['conv2d_422[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_417 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_417[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_422 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_422[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_418 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_417[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_423 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_422[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_418 (B  (None, 3, 3, 160)            480       ['conv2d_418[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_423 (B  (None, 3, 3, 160)            480       ['conv2d_423[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_418 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_418[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_423 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_423[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_40 (Aver  (None, 3, 3, 768)            0         ['mixed4[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_416 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed4[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_419 (Conv2D)         (None, 3, 3, 192)            215040    ['activation_418[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_424 (Conv2D)         (None, 3, 3, 192)            215040    ['activation_423[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_425 (Conv2D)         (None, 3, 3, 192)            147456    ['average_pooling2d_40[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_416 (B  (None, 3, 3, 192)            576       ['conv2d_416[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_419 (B  (None, 3, 3, 192)            576       ['conv2d_419[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_424 (B  (None, 3, 3, 192)            576       ['conv2d_424[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_425 (B  (None, 3, 3, 192)            576       ['conv2d_425[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_416 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_416[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_419 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_419[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_424 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_424[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_425 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_425[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 3, 3, 768)            0         ['activation_416[0][0]',      \n",
            "                                                                     'activation_419[0][0]',      \n",
            "                                                                     'activation_424[0][0]',      \n",
            "                                                                     'activation_425[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_430 (Conv2D)         (None, 3, 3, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_430 (B  (None, 3, 3, 160)            480       ['conv2d_430[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_430 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_430[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_431 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_430[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_431 (B  (None, 3, 3, 160)            480       ['conv2d_431[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_431 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_431[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_427 (Conv2D)         (None, 3, 3, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_432 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_431[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_427 (B  (None, 3, 3, 160)            480       ['conv2d_427[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_432 (B  (None, 3, 3, 160)            480       ['conv2d_432[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_427 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_427[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_432 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_432[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_428 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_427[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_433 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_432[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_428 (B  (None, 3, 3, 160)            480       ['conv2d_428[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_433 (B  (None, 3, 3, 160)            480       ['conv2d_433[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_428 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_428[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_433 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_433[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_41 (Aver  (None, 3, 3, 768)            0         ['mixed5[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_426 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_429 (Conv2D)         (None, 3, 3, 192)            215040    ['activation_428[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_434 (Conv2D)         (None, 3, 3, 192)            215040    ['activation_433[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_435 (Conv2D)         (None, 3, 3, 192)            147456    ['average_pooling2d_41[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_426 (B  (None, 3, 3, 192)            576       ['conv2d_426[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_429 (B  (None, 3, 3, 192)            576       ['conv2d_429[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_434 (B  (None, 3, 3, 192)            576       ['conv2d_434[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_435 (B  (None, 3, 3, 192)            576       ['conv2d_435[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_426 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_426[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_429 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_429[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_434 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_434[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_435 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_435[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 3, 3, 768)            0         ['activation_426[0][0]',      \n",
            "                                                                     'activation_429[0][0]',      \n",
            "                                                                     'activation_434[0][0]',      \n",
            "                                                                     'activation_435[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_440 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_440 (B  (None, 3, 3, 192)            576       ['conv2d_440[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_440 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_440[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_441 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_440[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_441 (B  (None, 3, 3, 192)            576       ['conv2d_441[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_441 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_441[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_437 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_442 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_441[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_437 (B  (None, 3, 3, 192)            576       ['conv2d_437[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_442 (B  (None, 3, 3, 192)            576       ['conv2d_442[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_437 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_437[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_442 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_442[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_438 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_437[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_443 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_442[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_438 (B  (None, 3, 3, 192)            576       ['conv2d_438[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_443 (B  (None, 3, 3, 192)            576       ['conv2d_443[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_438 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_438[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_443 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_443[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_42 (Aver  (None, 3, 3, 768)            0         ['mixed6[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_436 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_439 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_438[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_444 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_443[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_445 (Conv2D)         (None, 3, 3, 192)            147456    ['average_pooling2d_42[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_436 (B  (None, 3, 3, 192)            576       ['conv2d_436[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_439 (B  (None, 3, 3, 192)            576       ['conv2d_439[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_444 (B  (None, 3, 3, 192)            576       ['conv2d_444[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_445 (B  (None, 3, 3, 192)            576       ['conv2d_445[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_436 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_436[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_439 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_439[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_444 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_444[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_445 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_445[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 3, 3, 768)            0         ['activation_436[0][0]',      \n",
            "                                                                     'activation_439[0][0]',      \n",
            "                                                                     'activation_444[0][0]',      \n",
            "                                                                     'activation_445[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_448 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_448 (B  (None, 3, 3, 192)            576       ['conv2d_448[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_448 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_448[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_449 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_448[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_449 (B  (None, 3, 3, 192)            576       ['conv2d_449[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_449 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_449[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_446 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_450 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_449[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_446 (B  (None, 3, 3, 192)            576       ['conv2d_446[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_450 (B  (None, 3, 3, 192)            576       ['conv2d_450[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_446 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_446[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_450 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_450[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_447 (Conv2D)         (None, 1, 1, 320)            552960    ['activation_446[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_451 (Conv2D)         (None, 1, 1, 192)            331776    ['activation_450[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_447 (B  (None, 1, 1, 320)            960       ['conv2d_447[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_451 (B  (None, 1, 1, 192)            576       ['conv2d_451[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_447 (Activation  (None, 1, 1, 320)            0         ['batch_normalization_447[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_451 (Activation  (None, 1, 1, 192)            0         ['batch_normalization_451[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_19 (MaxPooli  (None, 1, 1, 768)            0         ['mixed7[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)        (None, 1, 1, 1280)           0         ['activation_447[0][0]',      \n",
            "                                                                     'activation_451[0][0]',      \n",
            "                                                                     'max_pooling2d_19[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_456 (Conv2D)         (None, 1, 1, 448)            573440    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_456 (B  (None, 1, 1, 448)            1344      ['conv2d_456[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_456 (Activation  (None, 1, 1, 448)            0         ['batch_normalization_456[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_453 (Conv2D)         (None, 1, 1, 384)            491520    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_457 (Conv2D)         (None, 1, 1, 384)            1548288   ['activation_456[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_453 (B  (None, 1, 1, 384)            1152      ['conv2d_453[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_457 (B  (None, 1, 1, 384)            1152      ['conv2d_457[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_453 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_453[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_457 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_457[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_454 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_453[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_455 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_453[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_458 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_457[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_459 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_457[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_43 (Aver  (None, 1, 1, 1280)           0         ['mixed8[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_452 (Conv2D)         (None, 1, 1, 320)            409600    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_454 (B  (None, 1, 1, 384)            1152      ['conv2d_454[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_455 (B  (None, 1, 1, 384)            1152      ['conv2d_455[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_458 (B  (None, 1, 1, 384)            1152      ['conv2d_458[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_459 (B  (None, 1, 1, 384)            1152      ['conv2d_459[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_460 (Conv2D)         (None, 1, 1, 192)            245760    ['average_pooling2d_43[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_452 (B  (None, 1, 1, 320)            960       ['conv2d_452[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_454 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_454[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_455 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_455[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_458 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_458[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_459 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_459[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_460 (B  (None, 1, 1, 192)            576       ['conv2d_460[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_452 (Activation  (None, 1, 1, 320)            0         ['batch_normalization_452[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)      (None, 1, 1, 768)            0         ['activation_454[0][0]',      \n",
            "                                                                     'activation_455[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate  (None, 1, 1, 768)            0         ['activation_458[0][0]',      \n",
            " )                                                                   'activation_459[0][0]']      \n",
            "                                                                                                  \n",
            " activation_460 (Activation  (None, 1, 1, 192)            0         ['batch_normalization_460[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)        (None, 1, 1, 2048)           0         ['activation_452[0][0]',      \n",
            "                                                                     'mixed9_0[0][0]',            \n",
            "                                                                     'concatenate_8[0][0]',       \n",
            "                                                                     'activation_460[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_465 (Conv2D)         (None, 1, 1, 448)            917504    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_465 (B  (None, 1, 1, 448)            1344      ['conv2d_465[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_465 (Activation  (None, 1, 1, 448)            0         ['batch_normalization_465[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_462 (Conv2D)         (None, 1, 1, 384)            786432    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_466 (Conv2D)         (None, 1, 1, 384)            1548288   ['activation_465[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_462 (B  (None, 1, 1, 384)            1152      ['conv2d_462[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_466 (B  (None, 1, 1, 384)            1152      ['conv2d_466[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_462 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_462[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_466 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_466[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_463 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_462[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_464 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_462[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_467 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_466[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_468 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_466[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_44 (Aver  (None, 1, 1, 2048)           0         ['mixed9[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_461 (Conv2D)         (None, 1, 1, 320)            655360    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_463 (B  (None, 1, 1, 384)            1152      ['conv2d_463[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_464 (B  (None, 1, 1, 384)            1152      ['conv2d_464[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_467 (B  (None, 1, 1, 384)            1152      ['conv2d_467[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_468 (B  (None, 1, 1, 384)            1152      ['conv2d_468[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_469 (Conv2D)         (None, 1, 1, 192)            393216    ['average_pooling2d_44[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_461 (B  (None, 1, 1, 320)            960       ['conv2d_461[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_463 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_463[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_464 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_464[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_467 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_467[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_468 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_468[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_469 (B  (None, 1, 1, 192)            576       ['conv2d_469[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_461 (Activation  (None, 1, 1, 320)            0         ['batch_normalization_461[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)      (None, 1, 1, 768)            0         ['activation_463[0][0]',      \n",
            "                                                                     'activation_464[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate  (None, 1, 1, 768)            0         ['activation_467[0][0]',      \n",
            " )                                                                   'activation_468[0][0]']      \n",
            "                                                                                                  \n",
            " activation_469 (Activation  (None, 1, 1, 192)            0         ['batch_normalization_469[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)       (None, 1, 1, 2048)           0         ['activation_461[0][0]',      \n",
            "                                                                     'mixed9_1[0][0]',            \n",
            "                                                                     'concatenate_9[0][0]',       \n",
            "                                                                     'activation_469[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_4 (Flatten)         (None, 2048)                 0         ['mixed10[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)        (None, 2048)                 0         ['flatten_4[0][0]']           \n",
            "                                                                                                  \n",
            " dense_12 (Dense)            (None, 4096)                 8392704   ['dropout_12[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)        (None, 4096)                 0         ['dense_12[0][0]']            \n",
            "                                                                                                  \n",
            " dense_13 (Dense)            (None, 1024)                 4195328   ['dropout_13[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)        (None, 1024)                 0         ['dense_13[0][0]']            \n",
            "                                                                                                  \n",
            " dense_14 (Dense)            (None, 8)                    8200      ['dropout_14[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34399016 (131.22 MB)\n",
            "Trainable params: 34364584 (131.09 MB)\n",
            "Non-trainable params: 34432 (134.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model_4 (Functional)        (None, 8)                 34399016  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34399016 (131.22 MB)\n",
            "Trainable params: 34364584 (131.09 MB)\n",
            "Non-trainable params: 34432 (134.50 KB)\n",
            "_________________________________________________________________\n",
            "True\n",
            "Epoch 1/10\n",
            "355/355 [==============================] - 81s 148ms/step - loss: 1.9645 - accuracy: 0.8721 - precision: 0.3962 - recall: 0.0445 - auc: 0.7826 - f1_score: 0.0723 - val_loss: 1.6218 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7909 - val_f1_score: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "355/355 [==============================] - 47s 133ms/step - loss: 1.6930 - accuracy: 0.8731 - precision: 0.3871 - recall: 0.0262 - auc: 0.7953 - f1_score: 0.0457 - val_loss: 1.5764 - val_accuracy: 0.8748 - val_precision: 0.2143 - val_recall: 5.2873e-04 - val_auc: 0.8089 - val_f1_score: 0.0010 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "355/355 [==============================] - 47s 133ms/step - loss: 1.6092 - accuracy: 0.8738 - precision: 0.4340 - recall: 0.0304 - auc: 0.8037 - f1_score: 0.0530 - val_loss: 1.6122 - val_accuracy: 0.8740 - val_precision: 0.3690 - val_recall: 0.0109 - val_auc: 0.8161 - val_f1_score: 0.0210 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "355/355 [==============================] - 47s 132ms/step - loss: 1.5685 - accuracy: 0.8742 - precision: 0.4583 - recall: 0.0332 - auc: 0.8148 - f1_score: 0.0586 - val_loss: 1.6206 - val_accuracy: 0.8688 - val_precision: 0.3571 - val_recall: 0.0619 - val_auc: 0.8018 - val_f1_score: 0.1046 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "355/355 [==============================] - 47s 132ms/step - loss: 1.5158 - accuracy: 0.8761 - precision: 0.5471 - recall: 0.0517 - auc: 0.8282 - f1_score: 0.0920 - val_loss: 1.7097 - val_accuracy: 0.8653 - val_precision: 0.3533 - val_recall: 0.0936 - val_auc: 0.7981 - val_f1_score: 0.1469 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "355/355 [==============================] - 47s 132ms/step - loss: 1.4871 - accuracy: 0.8779 - precision: 0.5606 - recall: 0.1058 - auc: 0.8374 - f1_score: 0.1742 - val_loss: 1.4278 - val_accuracy: 0.8833 - val_precision: 0.5990 - val_recall: 0.1999 - val_auc: 0.8490 - val_f1_score: 0.2980 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "355/355 [==============================] - 47s 133ms/step - loss: 1.4696 - accuracy: 0.8802 - precision: 0.5928 - recall: 0.1325 - auc: 0.8410 - f1_score: 0.2101 - val_loss: 1.5902 - val_accuracy: 0.8843 - val_precision: 0.5803 - val_recall: 0.2693 - val_auc: 0.8441 - val_f1_score: 0.3663 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "355/355 [==============================] - 47s 133ms/step - loss: 1.3709 - accuracy: 0.8897 - precision: 0.6354 - recall: 0.2760 - auc: 0.8629 - f1_score: 0.3781 - val_loss: 1.3244 - val_accuracy: 0.8917 - val_precision: 0.5825 - val_recall: 0.4706 - val_auc: 0.8756 - val_f1_score: 0.5201 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "355/355 [==============================] - 47s 132ms/step - loss: 1.3159 - accuracy: 0.8968 - precision: 0.6632 - recall: 0.3544 - auc: 0.8744 - f1_score: 0.4568 - val_loss: 1.6565 - val_accuracy: 0.8681 - val_precision: 0.4649 - val_recall: 0.3655 - val_auc: 0.8186 - val_f1_score: 0.4093 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "355/355 [==============================] - 47s 131ms/step - loss: 1.2966 - accuracy: 0.8986 - precision: 0.6751 - recall: 0.3637 - auc: 0.8783 - f1_score: 0.4656 - val_loss: 1.5937 - val_accuracy: 0.8626 - val_precision: 0.4434 - val_recall: 0.3884 - val_auc: 0.8334 - val_f1_score: 0.4141 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_acc = model.evaluate(test_dataset)\n",
        "print(test_acc)\n",
        "acc= history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc))\n",
        "\n",
        "plt.plot(epochs,acc,'r',label='Training Accuracy')\n",
        "plt.plot(epochs,val_acc,'b',label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "mXf7Z1y2Za5Y",
        "outputId": "361ae7a6-fbde-47c7-c1d7-8be17a08ec8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "111/111 [==============================] - 3s 29ms/step - loss: 1.5698 - accuracy: 0.8626 - precision: 0.4429 - recall: 0.3848 - auc: 0.8323 - f1_score: 0.4113\n",
            "[1.5698398351669312, 0.862586259841919, 0.4428594708442688, 0.3848429322242737, 0.8323136568069458, 0.4112946391105652]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "        validation_split = 0.2,\n",
        "        rotation_range=5,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  validation_split = 0.2)\n",
        "\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255\n",
        "                                  )\n",
        "\n",
        "train_dataset  = train_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                   target_size = (75,75),\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset = 'training',\n",
        "                                                   batch_size = 64)\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                  target_size = (75,75),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  subset = 'validation',\n",
        "                                                  batch_size = 64)\n",
        "\n",
        "test_dataset = test_datagen.flow_from_directory(directory = test_dir,\n",
        "                                                  target_size = (75,75),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  batch_size = 64)\n",
        "\n",
        "base_model = InceptionV3_mine(input_shape=(75,75,3), classes = 8)\n",
        "\n",
        "model=Sequential()\n",
        "model.add(base_model)\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "print(base_model.layers[18].trainable)\n",
        "\n",
        "def f1_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
        "    return f1_val\n",
        "\n",
        "METRICS = [\n",
        "      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      tf.keras.metrics.Precision(name='precision'),\n",
        "      tf.keras.metrics.Recall(name='recall'),\n",
        "      tf.keras.metrics.AUC(name='auc'),\n",
        "        f1_score,\n",
        "]\n",
        "\n",
        "lrd = ReduceLROnPlateau(monitor = 'val_loss',patience = 20,verbose = 1,factor = 0.50, min_lr = 1e-5)\n",
        "\n",
        "mcp = ModelCheckpoint('model.h5')\n",
        "\n",
        "es = EarlyStopping(verbose=1, patience=20)\n",
        "\n",
        "model.compile(optimizer='Adam', loss='categorical_crossentropy',metrics=METRICS)\n",
        "\n",
        "history=model.fit(train_dataset,validation_data=valid_dataset,epochs = 10,verbose = 1,callbacks=[lrd,mcp,es])\n",
        "\n",
        "test_acc = model.evaluate(test_dataset)\n",
        "print(test_acc)\n",
        "acc= history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc))\n",
        "\n",
        "plt.plot(epochs,acc,'r',label='Training Accuracy')\n",
        "plt.plot(epochs,val_acc,'b',label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "srnObNRjc5Da",
        "outputId": "d6f4583c-ddd3-4850-8d8c-841a822eaab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22712 images belonging to 8 classes.\n",
            "Found 5674 images belonging to 8 classes.\n",
            "Found 7099 images belonging to 8 classes.\n",
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_6 (InputLayer)        [(None, 75, 75, 3)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d_470 (Conv2D)         (None, 37, 37, 32)           864       ['input_6[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_470 (B  (None, 37, 37, 32)           96        ['conv2d_470[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_470 (Activation  (None, 37, 37, 32)           0         ['batch_normalization_470[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_471 (Conv2D)         (None, 35, 35, 32)           9216      ['activation_470[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_471 (B  (None, 35, 35, 32)           96        ['conv2d_471[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_471 (Activation  (None, 35, 35, 32)           0         ['batch_normalization_471[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_472 (Conv2D)         (None, 35, 35, 64)           18432     ['activation_471[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_472 (B  (None, 35, 35, 64)           192       ['conv2d_472[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_472 (Activation  (None, 35, 35, 64)           0         ['batch_normalization_472[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_20 (MaxPooli  (None, 17, 17, 64)           0         ['activation_472[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_473 (Conv2D)         (None, 17, 17, 80)           5120      ['max_pooling2d_20[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_473 (B  (None, 17, 17, 80)           240       ['conv2d_473[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_473 (Activation  (None, 17, 17, 80)           0         ['batch_normalization_473[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_474 (Conv2D)         (None, 15, 15, 192)          138240    ['activation_473[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_474 (B  (None, 15, 15, 192)          576       ['conv2d_474[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_474 (Activation  (None, 15, 15, 192)          0         ['batch_normalization_474[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_21 (MaxPooli  (None, 7, 7, 192)            0         ['activation_474[0][0]']      \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_478 (Conv2D)         (None, 7, 7, 64)             12288     ['max_pooling2d_21[0][0]']    \n",
            "                                                                                                  \n",
            " batch_normalization_478 (B  (None, 7, 7, 64)             192       ['conv2d_478[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_478 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_478[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_476 (Conv2D)         (None, 7, 7, 48)             9216      ['max_pooling2d_21[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_479 (Conv2D)         (None, 7, 7, 96)             55296     ['activation_478[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_476 (B  (None, 7, 7, 48)             144       ['conv2d_476[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_479 (B  (None, 7, 7, 96)             288       ['conv2d_479[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_476 (Activation  (None, 7, 7, 48)             0         ['batch_normalization_476[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_479 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_479[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_45 (Aver  (None, 7, 7, 192)            0         ['max_pooling2d_21[0][0]']    \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_475 (Conv2D)         (None, 7, 7, 64)             12288     ['max_pooling2d_21[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_477 (Conv2D)         (None, 7, 7, 64)             76800     ['activation_476[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_480 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_479[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_481 (Conv2D)         (None, 7, 7, 32)             6144      ['average_pooling2d_45[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_475 (B  (None, 7, 7, 64)             192       ['conv2d_475[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_477 (B  (None, 7, 7, 64)             192       ['conv2d_477[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_480 (B  (None, 7, 7, 96)             288       ['conv2d_480[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_481 (B  (None, 7, 7, 32)             96        ['conv2d_481[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_475 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_475[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_477 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_477[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_480 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_480[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_481 (Activation  (None, 7, 7, 32)             0         ['batch_normalization_481[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed0 (Concatenate)        (None, 7, 7, 256)            0         ['activation_475[0][0]',      \n",
            "                                                                     'activation_477[0][0]',      \n",
            "                                                                     'activation_480[0][0]',      \n",
            "                                                                     'activation_481[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean (TFOpL  (None, 7, 7, 1)              0         ['mixed0[0][0]']              \n",
            " ambda)                                                                                           \n",
            "                                                                                                  \n",
            " tf.math.reduce_max (TFOpLa  (None, 7, 7, 1)              0         ['mixed0[0][0]']              \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 7, 7, 2)              0         ['tf.math.reduce_mean[0][0]', \n",
            " e)                                                                  'tf.math.reduce_max[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_482 (Conv2D)         (None, 7, 7, 1)              98        ['concatenate_10[0][0]']      \n",
            "                                                                                                  \n",
            " multiply (Multiply)         (None, 7, 7, 256)            0         ['mixed0[0][0]',              \n",
            "                                                                     'conv2d_482[0][0]']          \n",
            "                                                                                                  \n",
            " attention0 (Lambda)         (None, 7, 7, 256)            0         ['multiply[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_486 (Conv2D)         (None, 7, 7, 64)             16384     ['attention0[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_485 (B  (None, 7, 7, 64)             192       ['conv2d_486[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_485 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_485[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_484 (Conv2D)         (None, 7, 7, 48)             12288     ['attention0[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_487 (Conv2D)         (None, 7, 7, 96)             55296     ['activation_485[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_483 (B  (None, 7, 7, 48)             144       ['conv2d_484[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_486 (B  (None, 7, 7, 96)             288       ['conv2d_487[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_483 (Activation  (None, 7, 7, 48)             0         ['batch_normalization_483[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_486 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_486[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_46 (Aver  (None, 7, 7, 256)            0         ['attention0[0][0]']          \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_483 (Conv2D)         (None, 7, 7, 64)             16384     ['attention0[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_485 (Conv2D)         (None, 7, 7, 64)             76800     ['activation_483[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_488 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_486[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_489 (Conv2D)         (None, 7, 7, 64)             16384     ['average_pooling2d_46[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_482 (B  (None, 7, 7, 64)             192       ['conv2d_483[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_484 (B  (None, 7, 7, 64)             192       ['conv2d_485[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_487 (B  (None, 7, 7, 96)             288       ['conv2d_488[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_488 (B  (None, 7, 7, 64)             192       ['conv2d_489[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_482 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_482[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_484 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_484[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_487 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_487[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_488 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_488[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed1 (Concatenate)        (None, 7, 7, 288)            0         ['activation_482[0][0]',      \n",
            "                                                                     'activation_484[0][0]',      \n",
            "                                                                     'activation_487[0][0]',      \n",
            "                                                                     'activation_488[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_1 (TFO  (None, 7, 7, 1)              0         ['mixed1[0][0]']              \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_1 (TFOp  (None, 7, 7, 1)              0         ['mixed1[0][0]']              \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_11 (Concatenat  (None, 7, 7, 2)              0         ['tf.math.reduce_mean_1[0][0]'\n",
            " e)                                                                 , 'tf.math.reduce_max_1[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_490 (Conv2D)         (None, 7, 7, 1)              98        ['concatenate_11[0][0]']      \n",
            "                                                                                                  \n",
            " multiply_1 (Multiply)       (None, 7, 7, 288)            0         ['mixed1[0][0]',              \n",
            "                                                                     'conv2d_490[0][0]']          \n",
            "                                                                                                  \n",
            " attention1 (Lambda)         (None, 7, 7, 288)            0         ['multiply_1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_494 (Conv2D)         (None, 7, 7, 64)             18432     ['attention1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_492 (B  (None, 7, 7, 64)             192       ['conv2d_494[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_492 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_492[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_492 (Conv2D)         (None, 7, 7, 48)             13824     ['attention1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_495 (Conv2D)         (None, 7, 7, 96)             55296     ['activation_492[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_490 (B  (None, 7, 7, 48)             144       ['conv2d_492[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_493 (B  (None, 7, 7, 96)             288       ['conv2d_495[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_490 (Activation  (None, 7, 7, 48)             0         ['batch_normalization_490[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_493 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_493[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_47 (Aver  (None, 7, 7, 288)            0         ['attention1[0][0]']          \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_491 (Conv2D)         (None, 7, 7, 64)             18432     ['attention1[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_493 (Conv2D)         (None, 7, 7, 64)             76800     ['activation_490[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_496 (Conv2D)         (None, 7, 7, 96)             82944     ['activation_493[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_497 (Conv2D)         (None, 7, 7, 64)             18432     ['average_pooling2d_47[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_489 (B  (None, 7, 7, 64)             192       ['conv2d_491[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_491 (B  (None, 7, 7, 64)             192       ['conv2d_493[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_494 (B  (None, 7, 7, 96)             288       ['conv2d_496[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_495 (B  (None, 7, 7, 64)             192       ['conv2d_497[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_489 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_489[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_491 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_491[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_494 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_494[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_495 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_495[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed2 (Concatenate)        (None, 7, 7, 288)            0         ['activation_489[0][0]',      \n",
            "                                                                     'activation_491[0][0]',      \n",
            "                                                                     'activation_494[0][0]',      \n",
            "                                                                     'activation_495[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_2 (TFO  (None, 7, 7, 1)              0         ['mixed2[0][0]']              \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_2 (TFOp  (None, 7, 7, 1)              0         ['mixed2[0][0]']              \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenat  (None, 7, 7, 2)              0         ['tf.math.reduce_mean_2[0][0]'\n",
            " e)                                                                 , 'tf.math.reduce_max_2[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_498 (Conv2D)         (None, 7, 7, 1)              98        ['concatenate_12[0][0]']      \n",
            "                                                                                                  \n",
            " multiply_2 (Multiply)       (None, 7, 7, 288)            0         ['mixed2[0][0]',              \n",
            "                                                                     'conv2d_498[0][0]']          \n",
            "                                                                                                  \n",
            " attention2 (Lambda)         (None, 7, 7, 288)            0         ['multiply_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_500 (Conv2D)         (None, 7, 7, 64)             18432     ['attention2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_497 (B  (None, 7, 7, 64)             192       ['conv2d_500[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_497 (Activation  (None, 7, 7, 64)             0         ['batch_normalization_497[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_501 (Conv2D)         (None, 7, 7, 96)             55296     ['activation_497[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_498 (B  (None, 7, 7, 96)             288       ['conv2d_501[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_498 (Activation  (None, 7, 7, 96)             0         ['batch_normalization_498[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_499 (Conv2D)         (None, 3, 3, 384)            995328    ['attention2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_502 (Conv2D)         (None, 3, 3, 96)             82944     ['activation_498[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_496 (B  (None, 3, 3, 384)            1152      ['conv2d_499[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_499 (B  (None, 3, 3, 96)             288       ['conv2d_502[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_496 (Activation  (None, 3, 3, 384)            0         ['batch_normalization_496[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_499 (Activation  (None, 3, 3, 96)             0         ['batch_normalization_499[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_22 (MaxPooli  (None, 3, 3, 288)            0         ['attention2[0][0]']          \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed3 (Concatenate)        (None, 3, 3, 768)            0         ['activation_496[0][0]',      \n",
            "                                                                     'activation_499[0][0]',      \n",
            "                                                                     'max_pooling2d_22[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_3 (TFO  (None, 3, 3, 1)              0         ['mixed3[0][0]']              \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_3 (TFOp  (None, 3, 3, 1)              0         ['mixed3[0][0]']              \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenat  (None, 3, 3, 2)              0         ['tf.math.reduce_mean_3[0][0]'\n",
            " e)                                                                 , 'tf.math.reduce_max_3[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_503 (Conv2D)         (None, 3, 3, 1)              98        ['concatenate_13[0][0]']      \n",
            "                                                                                                  \n",
            " multiply_3 (Multiply)       (None, 3, 3, 768)            0         ['mixed3[0][0]',              \n",
            "                                                                     'conv2d_503[0][0]']          \n",
            "                                                                                                  \n",
            " attention3 (Lambda)         (None, 3, 3, 768)            0         ['multiply_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_508 (Conv2D)         (None, 3, 3, 128)            98304     ['attention3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_504 (B  (None, 3, 3, 128)            384       ['conv2d_508[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_504 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_504[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_509 (Conv2D)         (None, 3, 3, 128)            114688    ['activation_504[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_505 (B  (None, 3, 3, 128)            384       ['conv2d_509[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_505 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_505[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_505 (Conv2D)         (None, 3, 3, 128)            98304     ['attention3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_510 (Conv2D)         (None, 3, 3, 128)            114688    ['activation_505[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_501 (B  (None, 3, 3, 128)            384       ['conv2d_505[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_506 (B  (None, 3, 3, 128)            384       ['conv2d_510[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_501 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_501[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_506 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_506[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_506 (Conv2D)         (None, 3, 3, 128)            114688    ['activation_501[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_511 (Conv2D)         (None, 3, 3, 128)            114688    ['activation_506[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_502 (B  (None, 3, 3, 128)            384       ['conv2d_506[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_507 (B  (None, 3, 3, 128)            384       ['conv2d_511[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_502 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_502[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_507 (Activation  (None, 3, 3, 128)            0         ['batch_normalization_507[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_48 (Aver  (None, 3, 3, 768)            0         ['attention3[0][0]']          \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_504 (Conv2D)         (None, 3, 3, 192)            147456    ['attention3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_507 (Conv2D)         (None, 3, 3, 192)            172032    ['activation_502[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_512 (Conv2D)         (None, 3, 3, 192)            172032    ['activation_507[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_513 (Conv2D)         (None, 3, 3, 192)            147456    ['average_pooling2d_48[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_500 (B  (None, 3, 3, 192)            576       ['conv2d_504[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_503 (B  (None, 3, 3, 192)            576       ['conv2d_507[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_508 (B  (None, 3, 3, 192)            576       ['conv2d_512[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_509 (B  (None, 3, 3, 192)            576       ['conv2d_513[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_500 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_500[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_503 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_503[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_508 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_508[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_509 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_509[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed4 (Concatenate)        (None, 3, 3, 768)            0         ['activation_500[0][0]',      \n",
            "                                                                     'activation_503[0][0]',      \n",
            "                                                                     'activation_508[0][0]',      \n",
            "                                                                     'activation_509[0][0]']      \n",
            "                                                                                                  \n",
            " tf.math.reduce_mean_4 (TFO  (None, 3, 3, 1)              0         ['mixed4[0][0]']              \n",
            " pLambda)                                                                                         \n",
            "                                                                                                  \n",
            " tf.math.reduce_max_4 (TFOp  (None, 3, 3, 1)              0         ['mixed4[0][0]']              \n",
            " Lambda)                                                                                          \n",
            "                                                                                                  \n",
            " concatenate_14 (Concatenat  (None, 3, 3, 2)              0         ['tf.math.reduce_mean_4[0][0]'\n",
            " e)                                                                 , 'tf.math.reduce_max_4[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " conv2d_514 (Conv2D)         (None, 3, 3, 1)              98        ['concatenate_14[0][0]']      \n",
            "                                                                                                  \n",
            " multiply_4 (Multiply)       (None, 3, 3, 768)            0         ['mixed4[0][0]',              \n",
            "                                                                     'conv2d_514[0][0]']          \n",
            "                                                                                                  \n",
            " attention4 (Lambda)         (None, 3, 3, 768)            0         ['multiply_4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_519 (Conv2D)         (None, 3, 3, 160)            122880    ['attention4[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_514 (B  (None, 3, 3, 160)            480       ['conv2d_519[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_514 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_514[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_520 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_514[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_515 (B  (None, 3, 3, 160)            480       ['conv2d_520[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_515 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_515[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_516 (Conv2D)         (None, 3, 3, 160)            122880    ['attention4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_521 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_515[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_511 (B  (None, 3, 3, 160)            480       ['conv2d_516[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_516 (B  (None, 3, 3, 160)            480       ['conv2d_521[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_511 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_511[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_516 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_516[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_517 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_511[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_522 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_516[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_512 (B  (None, 3, 3, 160)            480       ['conv2d_517[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_517 (B  (None, 3, 3, 160)            480       ['conv2d_522[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_512 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_512[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_517 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_517[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_49 (Aver  (None, 3, 3, 768)            0         ['attention4[0][0]']          \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_515 (Conv2D)         (None, 3, 3, 192)            147456    ['attention4[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_518 (Conv2D)         (None, 3, 3, 192)            215040    ['activation_512[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_523 (Conv2D)         (None, 3, 3, 192)            215040    ['activation_517[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_524 (Conv2D)         (None, 3, 3, 192)            147456    ['average_pooling2d_49[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_510 (B  (None, 3, 3, 192)            576       ['conv2d_515[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_513 (B  (None, 3, 3, 192)            576       ['conv2d_518[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_518 (B  (None, 3, 3, 192)            576       ['conv2d_523[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_519 (B  (None, 3, 3, 192)            576       ['conv2d_524[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_510 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_510[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_513 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_513[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_518 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_518[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_519 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_519[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed5 (Concatenate)        (None, 3, 3, 768)            0         ['activation_510[0][0]',      \n",
            "                                                                     'activation_513[0][0]',      \n",
            "                                                                     'activation_518[0][0]',      \n",
            "                                                                     'activation_519[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_529 (Conv2D)         (None, 3, 3, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_524 (B  (None, 3, 3, 160)            480       ['conv2d_529[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_524 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_524[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_530 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_524[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_525 (B  (None, 3, 3, 160)            480       ['conv2d_530[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_525 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_525[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_526 (Conv2D)         (None, 3, 3, 160)            122880    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_531 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_525[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_521 (B  (None, 3, 3, 160)            480       ['conv2d_526[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_526 (B  (None, 3, 3, 160)            480       ['conv2d_531[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_521 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_521[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_526 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_526[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_527 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_521[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_532 (Conv2D)         (None, 3, 3, 160)            179200    ['activation_526[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_522 (B  (None, 3, 3, 160)            480       ['conv2d_527[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_527 (B  (None, 3, 3, 160)            480       ['conv2d_532[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_522 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_522[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_527 (Activation  (None, 3, 3, 160)            0         ['batch_normalization_527[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_50 (Aver  (None, 3, 3, 768)            0         ['mixed5[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_525 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed5[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_528 (Conv2D)         (None, 3, 3, 192)            215040    ['activation_522[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_533 (Conv2D)         (None, 3, 3, 192)            215040    ['activation_527[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_534 (Conv2D)         (None, 3, 3, 192)            147456    ['average_pooling2d_50[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_520 (B  (None, 3, 3, 192)            576       ['conv2d_525[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_523 (B  (None, 3, 3, 192)            576       ['conv2d_528[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_528 (B  (None, 3, 3, 192)            576       ['conv2d_533[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_529 (B  (None, 3, 3, 192)            576       ['conv2d_534[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_520 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_520[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_523 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_523[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_528 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_528[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_529 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_529[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed6 (Concatenate)        (None, 3, 3, 768)            0         ['activation_520[0][0]',      \n",
            "                                                                     'activation_523[0][0]',      \n",
            "                                                                     'activation_528[0][0]',      \n",
            "                                                                     'activation_529[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_539 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_534 (B  (None, 3, 3, 192)            576       ['conv2d_539[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_534 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_534[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_540 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_534[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_535 (B  (None, 3, 3, 192)            576       ['conv2d_540[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_535 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_535[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_536 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_541 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_535[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_531 (B  (None, 3, 3, 192)            576       ['conv2d_536[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_536 (B  (None, 3, 3, 192)            576       ['conv2d_541[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_531 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_531[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_536 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_536[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_537 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_531[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_542 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_536[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_532 (B  (None, 3, 3, 192)            576       ['conv2d_537[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_537 (B  (None, 3, 3, 192)            576       ['conv2d_542[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_532 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_532[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_537 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_537[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " average_pooling2d_51 (Aver  (None, 3, 3, 768)            0         ['mixed6[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_535 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed6[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_538 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_532[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_543 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_537[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_544 (Conv2D)         (None, 3, 3, 192)            147456    ['average_pooling2d_51[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_530 (B  (None, 3, 3, 192)            576       ['conv2d_535[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_533 (B  (None, 3, 3, 192)            576       ['conv2d_538[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_538 (B  (None, 3, 3, 192)            576       ['conv2d_543[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_539 (B  (None, 3, 3, 192)            576       ['conv2d_544[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_530 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_530[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_533 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_533[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_538 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_538[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_539 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_539[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed7 (Concatenate)        (None, 3, 3, 768)            0         ['activation_530[0][0]',      \n",
            "                                                                     'activation_533[0][0]',      \n",
            "                                                                     'activation_538[0][0]',      \n",
            "                                                                     'activation_539[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_547 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_542 (B  (None, 3, 3, 192)            576       ['conv2d_547[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_542 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_542[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_548 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_542[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_543 (B  (None, 3, 3, 192)            576       ['conv2d_548[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_543 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_543[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_545 (Conv2D)         (None, 3, 3, 192)            147456    ['mixed7[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_549 (Conv2D)         (None, 3, 3, 192)            258048    ['activation_543[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_540 (B  (None, 3, 3, 192)            576       ['conv2d_545[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_544 (B  (None, 3, 3, 192)            576       ['conv2d_549[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_540 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_540[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_544 (Activation  (None, 3, 3, 192)            0         ['batch_normalization_544[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_546 (Conv2D)         (None, 1, 1, 320)            552960    ['activation_540[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_550 (Conv2D)         (None, 1, 1, 192)            331776    ['activation_544[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_541 (B  (None, 1, 1, 320)            960       ['conv2d_546[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_545 (B  (None, 1, 1, 192)            576       ['conv2d_550[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_541 (Activation  (None, 1, 1, 320)            0         ['batch_normalization_541[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_545 (Activation  (None, 1, 1, 192)            0         ['batch_normalization_545[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " max_pooling2d_23 (MaxPooli  (None, 1, 1, 768)            0         ['mixed7[0][0]']              \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " mixed8 (Concatenate)        (None, 1, 1, 1280)           0         ['activation_541[0][0]',      \n",
            "                                                                     'activation_545[0][0]',      \n",
            "                                                                     'max_pooling2d_23[0][0]']    \n",
            "                                                                                                  \n",
            " conv2d_555 (Conv2D)         (None, 1, 1, 448)            573440    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_550 (B  (None, 1, 1, 448)            1344      ['conv2d_555[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_550 (Activation  (None, 1, 1, 448)            0         ['batch_normalization_550[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_552 (Conv2D)         (None, 1, 1, 384)            491520    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_556 (Conv2D)         (None, 1, 1, 384)            1548288   ['activation_550[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_547 (B  (None, 1, 1, 384)            1152      ['conv2d_552[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_551 (B  (None, 1, 1, 384)            1152      ['conv2d_556[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_547 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_547[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_551 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_551[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_553 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_547[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_554 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_547[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_557 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_551[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_558 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_551[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_52 (Aver  (None, 1, 1, 1280)           0         ['mixed8[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_551 (Conv2D)         (None, 1, 1, 320)            409600    ['mixed8[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_548 (B  (None, 1, 1, 384)            1152      ['conv2d_553[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_549 (B  (None, 1, 1, 384)            1152      ['conv2d_554[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_552 (B  (None, 1, 1, 384)            1152      ['conv2d_557[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_553 (B  (None, 1, 1, 384)            1152      ['conv2d_558[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_559 (Conv2D)         (None, 1, 1, 192)            245760    ['average_pooling2d_52[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_546 (B  (None, 1, 1, 320)            960       ['conv2d_551[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_548 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_548[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_549 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_549[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_552 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_552[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_553 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_553[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_554 (B  (None, 1, 1, 192)            576       ['conv2d_559[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_546 (Activation  (None, 1, 1, 320)            0         ['batch_normalization_546[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_0 (Concatenate)      (None, 1, 1, 768)            0         ['activation_548[0][0]',      \n",
            "                                                                     'activation_549[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_15 (Concatenat  (None, 1, 1, 768)            0         ['activation_552[0][0]',      \n",
            " e)                                                                  'activation_553[0][0]']      \n",
            "                                                                                                  \n",
            " activation_554 (Activation  (None, 1, 1, 192)            0         ['batch_normalization_554[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9 (Concatenate)        (None, 1, 1, 2048)           0         ['activation_546[0][0]',      \n",
            "                                                                     'mixed9_0[0][0]',            \n",
            "                                                                     'concatenate_15[0][0]',      \n",
            "                                                                     'activation_554[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_564 (Conv2D)         (None, 1, 1, 448)            917504    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_559 (B  (None, 1, 1, 448)            1344      ['conv2d_564[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_559 (Activation  (None, 1, 1, 448)            0         ['batch_normalization_559[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_561 (Conv2D)         (None, 1, 1, 384)            786432    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_565 (Conv2D)         (None, 1, 1, 384)            1548288   ['activation_559[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_556 (B  (None, 1, 1, 384)            1152      ['conv2d_561[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_560 (B  (None, 1, 1, 384)            1152      ['conv2d_565[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_556 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_556[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_560 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_560[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " conv2d_562 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_556[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_563 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_556[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_566 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_560[0][0]']      \n",
            "                                                                                                  \n",
            " conv2d_567 (Conv2D)         (None, 1, 1, 384)            442368    ['activation_560[0][0]']      \n",
            "                                                                                                  \n",
            " average_pooling2d_53 (Aver  (None, 1, 1, 2048)           0         ['mixed9[0][0]']              \n",
            " agePooling2D)                                                                                    \n",
            "                                                                                                  \n",
            " conv2d_560 (Conv2D)         (None, 1, 1, 320)            655360    ['mixed9[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_557 (B  (None, 1, 1, 384)            1152      ['conv2d_562[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_558 (B  (None, 1, 1, 384)            1152      ['conv2d_563[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_561 (B  (None, 1, 1, 384)            1152      ['conv2d_566[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " batch_normalization_562 (B  (None, 1, 1, 384)            1152      ['conv2d_567[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " conv2d_568 (Conv2D)         (None, 1, 1, 192)            393216    ['average_pooling2d_53[0][0]']\n",
            "                                                                                                  \n",
            " batch_normalization_555 (B  (None, 1, 1, 320)            960       ['conv2d_560[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_557 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_557[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_558 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_558[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_561 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_561[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " activation_562 (Activation  (None, 1, 1, 384)            0         ['batch_normalization_562[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " batch_normalization_563 (B  (None, 1, 1, 192)            576       ['conv2d_568[0][0]']          \n",
            " atchNormalization)                                                                               \n",
            "                                                                                                  \n",
            " activation_555 (Activation  (None, 1, 1, 320)            0         ['batch_normalization_555[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed9_1 (Concatenate)      (None, 1, 1, 768)            0         ['activation_557[0][0]',      \n",
            "                                                                     'activation_558[0][0]']      \n",
            "                                                                                                  \n",
            " concatenate_16 (Concatenat  (None, 1, 1, 768)            0         ['activation_561[0][0]',      \n",
            " e)                                                                  'activation_562[0][0]']      \n",
            "                                                                                                  \n",
            " activation_563 (Activation  (None, 1, 1, 192)            0         ['batch_normalization_563[0][0\n",
            " )                                                                  ]']                           \n",
            "                                                                                                  \n",
            " mixed10 (Concatenate)       (None, 1, 1, 2048)           0         ['activation_555[0][0]',      \n",
            "                                                                     'mixed9_1[0][0]',            \n",
            "                                                                     'concatenate_16[0][0]',      \n",
            "                                                                     'activation_563[0][0]']      \n",
            "                                                                                                  \n",
            " flatten_5 (Flatten)         (None, 2048)                 0         ['mixed10[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)        (None, 2048)                 0         ['flatten_5[0][0]']           \n",
            "                                                                                                  \n",
            " dense_15 (Dense)            (None, 4096)                 8392704   ['dropout_15[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)        (None, 4096)                 0         ['dense_15[0][0]']            \n",
            "                                                                                                  \n",
            " dense_16 (Dense)            (None, 1024)                 4195328   ['dropout_16[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)        (None, 1024)                 0         ['dense_16[0][0]']            \n",
            "                                                                                                  \n",
            " dense_17 (Dense)            (None, 8)                    8200      ['dropout_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 34399506 (131.22 MB)\n",
            "Trainable params: 34365074 (131.09 MB)\n",
            "Non-trainable params: 34432 (134.50 KB)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " model_5 (Functional)        (None, 8)                 34399506  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 34399506 (131.22 MB)\n",
            "Trainable params: 34365074 (131.09 MB)\n",
            "Non-trainable params: 34432 (134.50 KB)\n",
            "_________________________________________________________________\n",
            "True\n",
            "Epoch 1/10\n",
            "355/355 [==============================] - 78s 137ms/step - loss: 1.9022 - accuracy: 0.8716 - precision: 0.3461 - recall: 0.0306 - auc: 0.7821 - f1_score: 0.0504 - val_loss: 1.6104 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.8002 - val_f1_score: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 2/10\n",
            "355/355 [==============================] - 47s 132ms/step - loss: 1.6831 - accuracy: 0.8730 - precision: 0.3830 - recall: 0.0256 - auc: 0.7940 - f1_score: 0.0439 - val_loss: 1.6092 - val_accuracy: 0.8746 - val_precision: 0.4024 - val_recall: 0.0058 - val_auc: 0.8038 - val_f1_score: 0.0113 - lr: 0.0010\n",
            "Epoch 3/10\n",
            "355/355 [==============================] - 47s 133ms/step - loss: 1.6317 - accuracy: 0.8739 - precision: 0.4142 - recall: 0.0207 - auc: 0.7975 - f1_score: 0.0370 - val_loss: 2.3987 - val_accuracy: 0.8617 - val_precision: 0.1205 - val_recall: 0.0169 - val_auc: 0.7585 - val_f1_score: 0.0296 - lr: 0.0010\n",
            "Epoch 4/10\n",
            "355/355 [==============================] - 47s 134ms/step - loss: 1.6135 - accuracy: 0.8745 - precision: 0.4460 - recall: 0.0180 - auc: 0.8018 - f1_score: 0.0331 - val_loss: 1.5846 - val_accuracy: 0.8748 - val_precision: 0.4516 - val_recall: 0.0074 - val_auc: 0.8053 - val_f1_score: 0.0143 - lr: 0.0010\n",
            "Epoch 5/10\n",
            "355/355 [==============================] - 47s 132ms/step - loss: 1.6219 - accuracy: 0.8741 - precision: 0.4335 - recall: 0.0228 - auc: 0.8019 - f1_score: 0.0406 - val_loss: 1.5834 - val_accuracy: 0.8749 - val_precision: 0.2727 - val_recall: 5.2873e-04 - val_auc: 0.8076 - val_f1_score: 0.0010 - lr: 0.0010\n",
            "Epoch 6/10\n",
            "355/355 [==============================] - 47s 133ms/step - loss: 1.6047 - accuracy: 0.8743 - precision: 0.4429 - recall: 0.0225 - auc: 0.8057 - f1_score: 0.0414 - val_loss: 1.5948 - val_accuracy: 0.8752 - val_precision: 0.6471 - val_recall: 0.0039 - val_auc: 0.8034 - val_f1_score: 0.0075 - lr: 0.0010\n",
            "Epoch 7/10\n",
            "355/355 [==============================] - 47s 132ms/step - loss: 1.5676 - accuracy: 0.8747 - precision: 0.4771 - recall: 0.0243 - auc: 0.8144 - f1_score: 0.0444 - val_loss: 1.6204 - val_accuracy: 0.8751 - val_precision: 1.0000 - val_recall: 5.2873e-04 - val_auc: 0.8005 - val_f1_score: 0.0010 - lr: 0.0010\n",
            "Epoch 8/10\n",
            "355/355 [==============================] - 47s 132ms/step - loss: 1.5646 - accuracy: 0.8750 - precision: 0.5000 - recall: 0.0229 - auc: 0.8147 - f1_score: 0.0425 - val_loss: 1.6499 - val_accuracy: 0.8750 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - val_auc: 0.7838 - val_f1_score: 0.0000e+00 - lr: 0.0010\n",
            "Epoch 9/10\n",
            "355/355 [==============================] - 48s 134ms/step - loss: 1.5637 - accuracy: 0.8749 - precision: 0.4894 - recall: 0.0122 - auc: 0.8139 - f1_score: 0.0232 - val_loss: 1.5351 - val_accuracy: 0.8764 - val_precision: 0.5727 - val_recall: 0.0437 - val_auc: 0.8215 - val_f1_score: 0.0798 - lr: 0.0010\n",
            "Epoch 10/10\n",
            "355/355 [==============================] - 47s 133ms/step - loss: 1.5336 - accuracy: 0.8760 - precision: 0.5768 - recall: 0.0291 - auc: 0.8237 - f1_score: 0.0547 - val_loss: 1.5823 - val_accuracy: 0.8752 - val_precision: 0.5414 - val_recall: 0.0127 - val_auc: 0.8072 - val_f1_score: 0.0245 - lr: 0.0010\n",
            "111/111 [==============================] - 3s 29ms/step - loss: 1.5991 - accuracy: 0.8752 - precision: 0.5455 - recall: 0.0110 - auc: 0.8032 - f1_score: 0.0212\n",
            "[1.5990657806396484, 0.8752288818359375, 0.5454545617103577, 0.010987463407218456, 0.8032170534133911, 0.021234748885035515]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wtLF4E-7eo7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2QoBsJPrepQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "        validation_split = 0.2,\n",
        "        rotation_range=5,\n",
        "        width_shift_range=0.2,\n",
        "        height_shift_range=0.2,\n",
        "        shear_range=0.2,\n",
        "        horizontal_flip=True,\n",
        "        vertical_flip=True,\n",
        "        fill_mode='nearest')\n",
        "\n",
        "valid_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                  validation_split = 0.2)\n",
        "\n",
        "test_datagen  = ImageDataGenerator(rescale = 1./255\n",
        "                                  )\n",
        "\n",
        "train_dataset  = train_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                   target_size = (224,224),\n",
        "                                                   class_mode = 'categorical',\n",
        "                                                   subset = 'training',\n",
        "                                                   batch_size = 64)\n",
        "\n",
        "valid_dataset = valid_datagen.flow_from_directory(directory = train_dir,\n",
        "                                                  target_size = (224,224),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  subset = 'validation',\n",
        "                                                  batch_size = 64)\n",
        "\n",
        "test_dataset = test_datagen.flow_from_directory(directory = test_dir,\n",
        "                                                  target_size = (224,224),\n",
        "                                                  class_mode = 'categorical',\n",
        "                                                  batch_size = 64)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_AsMCLAOepS1",
        "outputId": "5c5bd81c-d5a7-4628-c083-7a7bcfecd6cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 22712 images belonging to 8 classes.\n",
            "Found 5674 images belonging to 8 classes.\n",
            "Found 7099 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install timm\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IhkcavO71zz",
        "outputId": "03b23dd8-a034-4829-b1a7-443f8b9d451f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-1.0.3-py3-none-any.whl (2.3 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.3 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/2.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/2.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/2.3 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m2.1/2.3 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.18.0+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.23.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2023.6.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->timm)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->timm)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->timm)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->timm)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->timm)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->timm)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->timm)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->timm)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->timm)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, timm\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 timm-1.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iJIuTmAQepVb"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "import timm\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 检查 GPU 是否可用\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Using device: {device}')\n",
        "\n",
        "# 数据增强\n",
        "transform = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomRotation(5),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomVerticalFlip(),\n",
        "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'test': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# 数据加载\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=transform['train'])\n",
        "val_dataset = datasets.ImageFolder(root=train_dir, transform=transform['val'])\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=transform['test'])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# 模型定义\n",
        "model = timm.create_model('vit_small_patch16_224', pretrained=True, num_classes=8)\n",
        "model = model.to(device)\n",
        "\n",
        "# 打印模型是否在GPU上\n",
        "print(f'Model is on device: {next(model.parameters()).device}')\n",
        "\n",
        "# 损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# 使用混合精度训练\n",
        "scaler = GradScaler()\n",
        "\n",
        "# 训练和验证函数\n",
        "def train_model(model, criterion, optimizer, num_epochs=10):\n",
        "    best_model_wts = model.state_dict()\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # 每个 epoch 都有一个训练和验证阶段\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # 训练模式\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()  # 验证模式\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # 遍历数据\n",
        "            for inputs, labels in tqdm(dataloader, desc=f'{phase} phase'):\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # 前向传播\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    with autocast():\n",
        "                        outputs = model(inputs)\n",
        "                        _, preds = torch.max(outputs, 1)\n",
        "                        loss = criterion(outputs, labels)\n",
        "\n",
        "                    # 仅在训练阶段进行反向传播和优化\n",
        "                    if phase == 'train':\n",
        "                        optimizer.zero_grad()\n",
        "                        scaler.scale(loss).backward()\n",
        "                        scaler.step(optimizer)\n",
        "                        scaler.update()\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # 深拷贝模型\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = model.state_dict()\n",
        "\n",
        "        print()\n",
        "\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # 加载最佳模型权重\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model\n",
        "\n",
        "# 训练模型\n",
        "model = train_model(model, criterion, optimizer, num_epochs=10)\n",
        "\n",
        "# 测试模型\n",
        "model.eval()\n",
        "test_corrects = 0\n",
        "for inputs, labels in tqdm(test_loader, desc='Testing'):\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs)\n",
        "    _, preds = torch.max(outputs, 1)\n",
        "    test_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "test_acc = test_corrects.double() / len(test_loader.dataset)\n",
        "print(f'Test Accuracy: {test_acc:.4f}')\n"
      ],
      "metadata": {
        "id": "csdnCD_PfuI0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3bdd9d-6d8a-4b67-a339-d18ece719dc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Model is on device: cuda:0\n",
            "Epoch 0/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rtrain phase:   0%|          | 0/888 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py:456: UserWarning: Plan failed with a cudnnException: CUDNN_BACKEND_EXECUTION_PLAN_DESCRIPTOR: cudnnFinalize Descriptor Failed cudnn_status: CUDNN_STATUS_NOT_SUPPORTED (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:919.)\n",
            "  return F.conv2d(input, weight, bias, self.stride,\n",
            "train phase: 100%|██████████| 888/888 [02:02<00:00,  7.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.8438 Acc: 0.7033\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val phase: 100%|██████████| 888/888 [00:52<00:00, 16.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.5998 Acc: 0.7838\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train phase: 100%|██████████| 888/888 [02:01<00:00,  7.31it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.6117 Acc: 0.7808\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val phase: 100%|██████████| 888/888 [00:53<00:00, 16.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4735 Acc: 0.8283\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train phase: 100%|██████████| 888/888 [02:02<00:00,  7.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.5454 Acc: 0.8052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val phase: 100%|██████████| 888/888 [00:52<00:00, 16.78it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4323 Acc: 0.8420\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train phase: 100%|██████████| 888/888 [02:02<00:00,  7.27it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4973 Acc: 0.8201\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val phase: 100%|██████████| 888/888 [00:52<00:00, 16.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4743 Acc: 0.8291\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train phase: 100%|██████████| 888/888 [02:00<00:00,  7.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4673 Acc: 0.8290\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val phase: 100%|██████████| 888/888 [00:53<00:00, 16.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.4114 Acc: 0.8517\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train phase: 100%|██████████| 888/888 [02:01<00:00,  7.33it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train Loss: 0.4329 Acc: 0.8424\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "val phase: 100%|██████████| 888/888 [00:52<00:00, 16.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val Loss: 0.3524 Acc: 0.8742\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "train phase:  36%|███▌      | 321/888 [00:44<01:16,  7.46it/s]"
          ]
        }
      ]
    }
  ]
}